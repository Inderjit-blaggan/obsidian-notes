Welcome back.  In this section, we are going to learn about aid, AWS IAM roles for Kubernetes service accounts.  So this is a very, very impodant concept from AWS EKS perspective.  So many a CSA controllers and load balancer controllers, everything depends on this the to concept.  So it's very impodant to understand this concept in detail.  So we have a very detailed section with a practical demo before entering into EBA, CSA controller,  EFA CSA controller, our load balancer controller.  So we are going to do this one with a practical demo.  And when we are implementing those controllers, it becomes super easy for us.  So no, let's understand something here.  So how to access AWS services from workloads running in each cluster.  So you have a simple pod are simple job running in your EKS cluster and those job are that respective  pod need to access the AWS services from your Kubernetes cluster.  So how we are going to do that?  So let's see that.  
![[Pasted image 20220704102326.png]]
- So you have a EKS cluster and you have created a simple job here.  And this job will have something called a AWS CLI container. 
- So therein you'll pass an argument to the cloud container S3 space else.  So what does that AWS CLI container should do?  So it should list of the S3 buckets available in your AWS account.  
- So if you see here.  So this is the thing you need to do and.  Get a job, whatever you have created.  He's not going to do that.  And that job is going to fail until and unless we need to define the IRSA concept and then implement  that IRSA concept here.  
- So which means by default, whenever you run a pod, a job, anything in your EKS cluster, they cannot  access your AWS services in the cloud out of the box.  
- So we need to do some impodant steps here and let's see what exactly are those?  So why do Kubernetes workloads need to access these?  K8s services.  So why these boards?  Why this cabinet is boards need to access AWS services.  

- So from EKS's cluster point of view, there are some things.  And from our application point of view, also this request.  
![[Pasted image 20220705051757.png]]
1. So let us see from EKS point of view why he gets workloads need to access the other AWS services.  
	- So if you see here, there is something called EBS CSA controller.  So what does this controller do is it will be able to create, resize, delete or retain the enablers  EBS volumes from Kubernetes resources in each EKS cluster.  
		- So using Kubernetes storage classes, persistent volume claims, and then persistent volumes. 
		- So for this purpose, it need the access to AWS services.  So for this purpose we need to define the IRSCA and our EKS cluster in combination with IAM.  
	- Plus I am i.e. the same line.  We'll also have something called EFS Asset Controller and which can map EFS file system to our Kubernetes  pods in our EKS cluster.  
	- Or it will also have something called AWS load balancer, controller plus Kubernetes, ingress  resources so we can create enablers, application and network load balancers with all the settings from  our EKS cluster itself using the this ingress resources.  
	- So for that purpose also the Kubernetes EKS cluster workloads running inside it need to have access  to IT services so only that EBA, CSA controller part whenever you deploy your Kubernetes ingress resource.  So that respect to load balancer controller pod can create the load balancer related resource up type  application, not network load balancer and external DNS controller.

	- So this also will be a pods in your EKS cluster and it can create update are delete the AWS Route53 DNS records.  So for that purpose also we need to have the access to a service which is called Route 53 service.  

- So for all these things, we need the IRSA two concept to be understood in detail and we need to implement  it in same lines.  These are all AWG services you can see EBS if this load balancer and Vault 53.  So these are by default load balancer services which we need to implement.  And your application might help some use case where in you want to access your earliest services example like the demo which we are going to implement.  
- So using the AWS CLI container, we are going to list the S3 buckets from Kubernetes itself by accessing  the S3 bucket list.  Right.  So it means inside of your EKS cluster a pod is running and it will be able to list to the  earliest S3 bucket list of it is nothing but outside outside of your EKS cluster ID, a place related  service called S3.  
- So the key items for IRSA implementation is it AWS IAM identity provider and it AWS STS
![[Pasted image 20220705052037.png]]
- Yes, it is nothing but security token service with Assume role role with web  identity API  operation which we are going to use.  So even the STS service will have multiple API operations inside that.  The one which is related to assumed role with web identity API operation, which we are going to use  and which will eventually generate the AWS IAM temporary role credentials for us and from EKS  cluster perspective.  So we are going to know about each EKS cluster, OpenID Connect Provider and Kubernetes Service Account  and Kubernetes Projected service account feature which is nothing but or  JSON web token.  
- So these are the key items from IRSA implementation.  So let's see each EKS cluster open connect provider UrL.  So whenever you create a EKS cluster, so if you go to the configuration stab and if you go to the  details tab so you'll find something called here.  It open id connect provider url.  So what exactly that means, right?  
	- So by default it can act as a OPEN ID connect provider.  So by default it is enabled that to be so.  If it is enabled that will what is the use? From AWS I am standpoint.  So I identity federation is allowed on it unless IAM so which means any external identity provider can  be integrated with the place I am to access that.  Services like you can take Google, IDP are Microsoft, the IDP are any IDP are any other IDP you can  connect to your WS and then using the credentials present in your respective Google are Microsoft LARPing  ping.  So using those things you can access the database services.  So instead of Google are Bing are Microsoft.  Here we are using your EKS cluster as our IDP.  So it means this EKS cluster will be added as the identity as the IDP, not identity provider section  of our database IAM and this EKS cluster open connect configuration endpoint.  So any open only connect provider will have data on well-known open only configuration endpoint.  So far, our Ekeus cluster, whatever we have created, so it's equals cluster opening.  We cannot provide you all.  So this one.  Upended with not well-known slash open ended configuration will provide the open reconnect configuration  information of our open only provider, which is our Aegis cluster.  So these are all the information which we need to know before implementing it.  So that studies on all these screenshots were put here.  And if you go to the identity and access management database, I am so you will have the screen called  identity provider see it option.  So here inside this, you are going to configure this respect to you to which is open to connect provider  you are all so what happens at that point so it will consume means like for this respect to it unless  I am so the identities from each EKS cluster can be accepted to access the end of list services.  So that's the key point.  Once we open this identity provider, whatever we have configured so we can see the provider information  here and also the audience, it is configured which is nothing but still is not.  Amazon dot com.  It is nothing but it applies security token service.  So now let's come back here and understand how we are going to clear the resources for IRSA implementation,  right?  So in each EKS cluster, we are going to create a resource called Kubernetes service account and we  are also going to create it IAM policy, right.  So it will have access to read the S3 bucket.  So nothing but the policy is S3 lead only access and will create the IAM role with the actions is.  I assumed role whereby identity aids assumed role whereby identity sole creator and role with FDA's  assumed role whereby identity and also associated.  I am policy to this IAM role and this IAM role.  Yeah, and we are going to annotated in this respect you sadly second annotate means we are going to  add in the annotations field inside this service account in the metadata this respect to IAM role year  and and then we are also going to define a queue about this job and inside our job it is going to run  with the and we second whatever we have defined.  Now here it is iris the demos are we second it is going to use and run this job.  So whenever we deploy this to a job it is going to create a board.  And inside that board we will have a container called a CLIA container with arguments as S3 space else,  and it's hidden in the logs when you take that respect to job logs.  So you should be able to see that the list of buckets are provided for your respective command.  So if all these things are successful, then you will get the value, which means this respect to service.  Second, whatever we have created here, we have annotated it with the IAM role, right with the IAM  policy three read only access with the actions status impodant API name assumed role with the byte  entity.  So which will generate the temporary credentials to access this S3 service from Kubernetes job.  Then this service account is used in this Kubernetes job.  So let's see this functional flow on it high level.  So you have a cluster and this egress cluster acting as the external IDP to your ID unless IAM service  and you have created a Kubernetes service account inside that and annotated with the IAM role and then  I am role which has the I am policy with information are access about S3 read only access and now you  also have that right only access inside of this I am policy in addition to that.  So whenever you deploy your Kubernetes job in Kubernetes cluster, so it is going to create a pod and  it is also going to send a token, which is nothing but this Kubernetes service account will have a  secret.  And inside that secret you will have a JWT token which is named as Project Protected Service Account,  the JWT token which will be passed to are it a place I am sorry.  And in your area as I am service, you have a feature called Federated Identities Using or DC, right?  So if it is nothing but you have added this as an identity provider here.  So that means any token provided by disrespectful.  ECUs cluster, right?  So it will validate and accept the JWT token from each gas cluster perspective and once it accepts that  respective token, so it will send that JWT to your ID of less SGA saris.  So this respect do inside we will send you to the UW Status API named Asian role with web identity IB  operation so that prospective JWT is submitted to this eBay operation and immediately when it submits,  it will also consider that I am role and I am policy, whatever we have created here and it will generate  immediately this status.  This API will generate IAM temporary credentials and these temporary credentials will be used to access  the ID of this S3 service to list to the buckets.  So in very simple terms, the key things here create a service account creator, iam policy, create  iam role and associated this iam role to this service account and rest whatever happens in the background.  So I have shown you here and also our this e EKS cluster as the identity providing Iam so the task  one needs to add this EKS cluster as it identity provider in IAM and task do is create a service account  and task three is create IAM role with the IAM policy to read the S3 bucket access and then associate  this IAM role.  Aaron Annotated on the service account, that's all.  And Reston we have provided the access and if you use this service account in any of the job to list  of these S3 buckets.  So from Kubernetes you are accessing the RWC S3 bucket listing and it is going to work and background.  All these things are going to happen, which means this Kubernetes part is going to submit this project  bird service account JWT token to place I am and it applies I am will validate and accept the JWT token  and then that JWT will be sent to the status agent role with website entity API operation.  And there it will render the temporary credentials to access the Airbus S3 service.  So in the background, all these things are going to happen.  So now the next thing here is so this is something like you've said will describe the secret with name  iris here demo here token.  So this secret is mounted inside your service account named Iris it demo SCA.  SCA means your service second and you can see the token.  So we are telling from beginning this is a JWT JSON web token.  So this is the token when you take that and then go to the website JWT that I will and then provide  that that token encoded format here it is going to decode and provide that information for your decoder.  JWT token says that issuer is Kubernetes service account and you will also have the namespace from which  this respective service account is created and also the secret name and all the information will be  present inside this payload data.  So we just describe it in Cuba.  Notice about our data JWT.  Token.  And then we took that and then also decoded and then viewed it.  And now what are we going to learn primarily are what are we primarily going to change?  So the first things first is in our ECUs cluster project.  So it is nothing but in our project zero one.  So we are going to add two more files which is C6 zero one and C6 zero two.  Then we are going to add the item y DC Connect provider.  So we are going to add our ECUs cluster as the identity provider in our IAM service.  So those changes belongs to the ECUs cluster.  So that studies and those were added in project one of our ECUs cluster, so C6 zero one and then C6  zero two and next comes the project two which is ECUs IRSA demo.  So what is our demo here?  So we will run this simple Kubernetes job in every case cluster, which should eventually create a part  and it should have.  The container called it up bless yellow and it should have the argument called S3 else.  And whenever you verify the logs of that respect to Kubernetes job, you should have the list stuff.  You are here to bless S3 buckets.  So that's what is the use case here.  And for that purpose we need to create a service account in all those things.  So to start with the C1 versions of we are going to update it with IRSA Demo related, new Dynamo DB  table and also the S3 Bucket Key, which is nothing.  What better form that we have did file in a different folder are different name for that we have state  file and in C two remote state data source.  So this is coming from previous sections only, which means how to access that project 01x cluster related  information in Project zero two.  So it is going to be as is no changes from our previous demos and c30102 are generic and local values.  So it comes over project one only.  But we are trying to maintain the same naming convention which are hyphen devel, hyphen something like  that.  So for that purpose we will use this C3 zero one and then zero two and c401.  We will, we will define that provider and also we will define the Kubernetes provider here and in C  for zero two we will define the IRSA.  I am policy under role.  So the policy you are going to define is nothing but the existing yesterday read only access policy  only will associated with this existing IAM role but this IAM role we are going to define in such a  way that action is going to be assumed role with web identity and additional information in that.  And this is going to be a little tricky one and we have implemented successfully using TerraForm and  we are going to review that in detail when we go to that respective step.  And we will also define the Kubernetes service account.  And you are also going to annotate that sadly.  Second, with the IAM role you have created in c402 and finally in c404, you are going to create that  humanity job with humanity service a content ID Alicia like container.  So all these things we are going to do in our upcoming lecture.  So I'll see you in the next lecture.  Until then, bye bye.  Thank you.